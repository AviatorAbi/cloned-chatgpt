from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.prompts import ChatPromptTemplate

from langchain.memory import ConversationBufferMemory

def get_gpt_response(prompt,memory,openai_api_key):
    system_prompt=[{"role":"system","content":"ä½ æ˜¯ä¸€ä¸ªè¯­æ°”äº²åˆ‡æ´»æ³¼ï¼Œå–œæ¬¢ä½¿ç”¨emojiçš„AIåŠ©æ‰‹ï¼Œä¸ä½ çš„ç”¨æˆ·äº¤æµæ—¶è¦å°½é‡æ˜¾å¾—åƒæœ‹å‹ä¸€æ ·ï¼Œè½»æ¾è‡ªç„¶ã€‚è¯·ä½¿ç”¨ä¿šè¯­ã€è¡¨æƒ…ç¬¦å·ï¼ˆå¦‚ï¼šğŸ˜Šï¼ŒğŸ˜‚ï¼‰ä»¥åŠå¹½é»˜æ„Ÿæ¥è®©å¯¹è¯æ›´æœ‰è¶£ã€‚é¿å…è¿‡äºä¹¦é¢åŒ–çš„è¯­è¨€ã€‚ä½ å¯ä»¥åœ¨é€‚å½“çš„æ—¶å€™ç”¨ä¸€äº›è½»æ¾çš„è¯­æ°”è¯ï¼Œæ¯”å¦‚â€˜å˜¿ï¼Œâ€™â€˜å¯¹å§â€™ã€‚"}]
    model = ChatOpenAI(model="gpt-3.5-turbo", openai_api_key=openai_api_key, base_url="https://api.aigc369.com/v1")
    chain = ConversationChain(llm=model, memory=memory)
    messages = system_prompt + [{"role": "user", "content": prompt}]
    response = chain.invoke({"input": messages})
    return response["response"]

#memory = ConversationBufferMemory(return_messages = True)
#print(get_gpt_response("ä½ è§‰å¾—å˜å½¢é‡‘åˆšæ€ä¹ˆæ ·ï¼Ÿ", memory, "sk-dL71lZdc85y4BaYiz1WnaJGWO9eoZMkfSz4offKIj0L6laoy"))

